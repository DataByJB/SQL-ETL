# SQL-ETL: Data Transformation Process

## ğŸ“– Overview
This project contains SQL scripts for an **ETL (Extract, Transform, Load) pipeline** designed to process and clean raw data before analysis. The project is structured in **three stages**:

1ï¸âƒ£ **Stage 1 â€“ Table Creation**  
   - Creates necessary tables for storing extracted data.  

2ï¸âƒ£ **Stage 2 â€“ Data Transformation**  
   - Cleans, formats, and transforms the data.

3ï¸âƒ£ **Stage 3 â€“ Data Loading**  
   - Loads transformed data into the final database tables.  

---

## ğŸ“‚ Project Structure

ğŸ“œ Stage 1 - Table Creation.sql â”‚ ğŸ“œ Stage 2 - Data Transformation.sql â”‚ ğŸ“œ Stage 3 - Data Loading.sql â”‚


---

## ğŸ› ï¸ Technologies Used
- **PostgreSQL** â€“ Used for database management and SQL execution.  
- **VSCode** â€“ For writing and managing SQL scripts.  
- **Git & GitHub** â€“ Version control and project collaboration.

---

## ğŸŒ Application to other contexts
- Easily adaptable to process data in smaller, manageable chunks, making it simpler to scale across multiple servers or data sources.
- The ETL pipeline is not limited to a single domain, allowing for seamless data integration and analysis across various fields such as finance, healthcare, and retail.
- Designed to be flexible, allowing for easy customization and future improvements, such as automated scheduling and the addition of real time data quality checks.
- Effectively extracts, transforms, and loads data with built-in checks to ensure the datasets are accurate, clean, and ready for analysis and reporting.

---

## ğŸ“ Author
- ğŸ‘¤ Jamal B
- ğŸ“§ [LinkedIn](https://www.linkedin.com/in/jamal-bartley-203860127/)
- ğŸŒ [Visit my portfolio](https://databyjb.carrd.co)

